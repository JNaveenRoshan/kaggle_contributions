{"cells":[{"metadata":{"trusted":true},"cell_type":"markdown","source":"## The Workflow/Steps Followed in this Notebook for a simple Image Classification using Keras\n\n> Step 1 : Getting the data ready\n\n> Step 2 : Turning the data into tensors\n\n> Step 3 : Building the model \n\n> Step 4 : Making predictions on the test data\n\n"},{"metadata":{},"cell_type":"markdown","source":"## **Step 1:Getting the data ready**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Import all the necessary packages needed for your problem\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport pandas as pd\nimport numpy as np\nimport os ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As the training,validation,test data each has two different folders named Male and Female we need to combine them and make them as a single data frame for training,validation,test data frame "},{"metadata":{"trusted":true},"cell_type":"code","source":"#As there are two folder storing their file path in two different variables\nTrain_female_path=\"../input/gender-recognition-200k-images-celeba/Dataset/Train/Female\"\nTrain_male_path=\"../input/gender-recognition-200k-images-celeba/Dataset/Train/Male\"\nValidation_female_path=\"../input/gender-recognition-200k-images-celeba/Dataset/Validation/Female\"\nValidation_male_path=\"../input/gender-recognition-200k-images-celeba/Dataset/Validation/Male\"\nTest_female_path=\"../input/gender-recognition-200k-images-celeba/Dataset/Test/Female\"\nTest_male_path=\"../input/gender-recognition-200k-images-celeba/Dataset/Test/Male\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a list to store all the training male and female filepaths\n\nfemale_train_files=[]\nfemale_train=list()\nmale_train=list()\n# listdir lists all the files in the given file path and stores it in the list\nfemale_train_files=os.listdir(Train_female_path)\nmale_train_files=os.listdir(Train_male_path)\n# As for now we only get the file name as in (01.jpg) so appending the file path with the filename\nfor i in range(len(os.listdir(Train_female_path))):\n    female_train.append(Train_female_path+\"/\"+str(female_train_files[i]))\nfor i in range(len(os.listdir(Train_male_path))):\n    male_train.append(Train_male_path+\"/\"+str(male_train_files[i]))\n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for the entire size of the training data\nlen(female_train)+len(male_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train_df=pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a training data frame with female images path and their target value as Female\nTrain_df=pd.DataFrame({\"ID\":female_train,\"Target\":\"Female\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(Train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train_df[\"ID\"][0],Train_df[\"Target\"][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Dataframe from male file path and assigning their as Male\nMale_df=pd.DataFrame({\"ID\":male_train,\"Target\":\"Male\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combining the male and female training dataframe\nTrain_df=Train_df.append(Male_df,ignore_index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(Train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shuffling the entire data frame as their in the female first and male last order\nTrain_df=Train_df.sample(frac=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fetching all the file names from Training dataframe and storing it as list\nAll_training_files=[fname for fname in Train_df[\"ID\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"All_training_files[:7]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting the target variable to num py\nlabels=Train_df[\"Target\"].to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding the unique values in the labels as there is only two target that needs to be predicted\ntrue_labels=np.unique(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(true_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels[1]==true_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boolean_labels=[labels == true_labels for labels in labels]\nlen(boolean_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(labels[0])\nprint(np.where(true_labels[0]==labels[0]))\nprint(boolean_labels[0].argmax())\nprint(boolean_labels[0].astype(int))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boolean_labels[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating the Feature variable and Target variable\nX=All_training_files\ny=boolean_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Experimenting with 10k samples \nNUM_IMAGES=10000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"female_val_files=[]\nfemale_val=list()\nmale_val=list()\n#Storing  all the files in given file path into two variables\nfemale_val_files=os.listdir(Validation_female_path)\nmale_val_files=os.listdir(Validation_male_path)\n# Appending the filepath with the file name\nfor i in range(len(os.listdir(Validation_female_path))):\n    female_val.append(Validation_female_path+\"/\"+str(female_val_files[i]))\nfor i in range(len(os.listdir(Validation_male_path))):\n    male_val.append(Validation_male_path+\"/\"+str(male_val_files[i]))\n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"female_val[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a dataframe for male and female\nValid_df=pd.DataFrame({\"ID\":female_val,\"Target\":\"Female\"})\nnew_val_row=pd.DataFrame({\"ID\":male_val,\"Target\":\"Male\"})\n# Combining the both \nValid_df=Valid_df.append(new_val_row,ignore_index=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Valid_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Shuffling the data\nValid_df=Valid_df.sample(frac=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Valid_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting  all the file paths from validation dataframe\nAll_val_files=[fname for fname in Valid_df[\"ID\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"All_val_files[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_labels=Valid_df[\"Target\"].to_numpy()\nval_labels[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_true_labels=np.unique(val_labels)\nlen(val_true_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boolean_val_labels=[labels==val_true_labels for labels in val_labels ]\nboolean_val_labels[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting data into training and validation set\nX_train,y_train=All_training_files[:NUM_IMAGES],boolean_labels[:NUM_IMAGES]\nX_val,y_val=All_val_files[:2000],boolean_val_labels[:2000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 2: Turning the data into tensors"},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SIZE=224\n# Creating a function that can preprocess the data\ndef preprocess_data(image_path,img_size=IMG_SIZE):\n    #Reading the image path\n    image=tf.io.read_file(image_path)\n    #Turning the image into numerical tensors of colour channel\n    image=tf.image.decode_jpeg(image,channels=3)\n    #Converting the colour channels from 0-255 values to 0-1\n    image=tf.image.convert_image_dtype(image,tf.float32)\n    #Resize our images into the desired value 224\n    image=tf.image.resize(image,size=[IMG_SIZE,IMG_SIZE])\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to return a tuple of preprocessed image in form tensors and their respective labels\ndef get_image_label(image_path,label):\n    image=preprocess_data(image_path)\n    return image,label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to change all our X and y into data batches\nBATCH_SIZE=32\ndef create_data_batches(X,y=None,batch_size=BATCH_SIZE,valid_data=False,test_data=False):\n    # if it is training data then there won't be lables\n    if test_data==True:\n        print(\"Create test data batches....\")\n        data=tf.data.Dataset.from_tensor_slices((tf.context(X)))\n        data_batch=data.map(preprocess_data).batch(BATCH_SIZE)\n        return data_batch\n    # if it is valid data\n    elif valid_data==True:\n        print(\"Create validation data batches.....\")\n        data=tf.data.Dataset.from_tensor_slices((tf.constant(X),tf.constant(y)))\n        data_batch=data.map(get_image_label).batch(BATCH_SIZE)\n        return data_batch\n    # if it is training data\n    else:\n        print(\"Creating training data batches....\")\n        data=tf.data.Dataset.from_tensor_slices((tf.constant(X),tf.constant(y)))\n        data=data.map(get_image_label)\n        data_batch=data.batch(BATCH_SIZE)\n        return data_batch\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X_train),len(X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create training and validation data batches\ntrain_data=create_data_batches(X_train,y_train)\nval_data=create_data_batches(X_val,y_val,valid_data=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.element_spec,val_data.element_spec","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizing the data batches"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef show_25_images(images,label):\n    # setup a figure \n    plt.figure(figsize=(10,10))\n    # loop through 25 images\n    for i in range(25):\n        # Create subplots (5 rows,5 columns)\n        ax=plt.subplot(5,5,i+1)\n        # Display an image\n        plt.imshow(images[i])\n        # Add image label as title\n        plt.title(true_labels[label[i].argmax()])\n        # Turn the grid lines off\n        plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(val_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unbatch the data using as_numpy_iterator\ntrain_images,train_labels=next(train_data.as_numpy_iterator())\n# Now lets visualize the images in the training batch\nshow_25_images(train_images,train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now lets visualize the images in the validation batch\nval_images,val_labels=next(val_data.as_numpy_iterator())\nshow_25_images(val_images,val_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 3: Building a machine learning model"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# Setting up a input shape\nINPUT_SHAPE=[None,IMG_SIZE,IMG_SIZE,3]\n\n# Settion up a output shape\nOUTPUT_SHAPE=len(true_labels)\n\n# Model URL\nMODEL_URL=\"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building a keras model\ndef create_model(input_shape=INPUT_SHAPE,output_shape=OUTPUT_SHAPE,model_url=MODEL_URL):\n    model=tf.keras.Sequential([\n        hub.KerasLayer(MODEL_URL),\n        tf.keras.layers.Dense(units=OUTPUT_SHAPE,\n                             activation=\"softmax\")\n    ])\n    \n    model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n      optimizer=tf.keras.optimizers.Adam(),\n      metrics=[\"accuracy\"]\n\n  )\n\n    # Build the model\n    model.build(INPUT_SHAPE)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=create_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%load_ext tensorboard","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a early stopping callback\nearly_stopping=tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",patience=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_EPOCHS=100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\n# Create a function to build a TensorBoard Callback\ndef create_tensorboard_callback():\n    # Create a log directory for storing TensorBoard logs\n    logdir=os.path.join(\"./kaggle/working/\",\n                      # Make it so the logs gets tracked whenever we run the expirement\n                      datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n    return tf.keras.callbacks.TensorBoard(logdir) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build a function to train a model and return a trained model\ndef train_model():\n    # Create a model\n    model=create_model()\n\n    # Create a new session everytime we train a model\n    tensorboard=create_tensorboard_callback()\n\n    # Fit the model to the data passing it the callbacks we created\n    model.fit(x=train_data,\n            epochs=NUM_EPOCHS,\n            validation_data=val_data,\n            validation_freq=1,\n            callbacks=[tensorboard,early_stopping])\n    return model\n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=train_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(val_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make Predictions on the validation data\npredictions=model.predict(val_data,verbose=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(predictions[0])\nprint(f\"Max value (probability of prediction): {np.max(predictions[0])}\") # the max probability value predicted by the model\nprint(f\"Max index: {np.argmax(predictions[0])}\") # the index of where the max value in predictions[0] occurs\nprint(f\"Predicted label: {true_labels[np.argmax(predictions[0])]}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Turn prediction probabilities into their respective label (easier to understand)\ndef get_pred_label(prediction_probabilities):\n  \"\"\"\n  Turns an array of prediction probabilities into a label.\n  \"\"\"\n  return true_labels[np.argmax(prediction_probabilities)]\n\n# Get a predicted label based on an array of prediction probabilities\npred_label = get_pred_label(predictions[0])\npred_label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(val_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a function to unbatch a batched dataset\ndef unbatchify(data):\n    \n    images = []\n    labelss = []\n    # Loop through unbatched data\n    for image, label in data.unbatch().as_numpy_iterator():\n        images.append(image)\n        labelss.append(true_labels[np.argmax(label)])\n    return images, labelss\n\n# Unbatchify the validation data\nval_images, val_labels = unbatchify(val_data)\nval_images[0], val_labels[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(val_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_pred(prediction_probabilities, labels, images, n=0):\n    \n    pred_prob, true_label, image = prediction_probabilities[n], labels[n], images[n]\n  \n    # Get the pred label\n    pred_label = get_pred_label(pred_prob)\n  \n  # Plot image & remove ticks\n    plt.imshow(image)\n    plt.xticks([])\n    plt.yticks([])\n\n  # Change the color of the title depending on if the prediction is right or wrong\n    if pred_label == true_label:\n        color = \"green\"\n    else:\n        color = \"red\"\n\n    plt.title(\"{} {:2.0f}% ({})\".format(pred_label,\n                                      np.max(pred_prob)*100,\n                                      true_label),\n                                      color=color)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(val_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pred(prediction_probabilities=predictions,\n          labels=val_labels,\n          images=val_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(val_data)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Note:** \nI tried training my model with the entire training dataset (i.e 160k images) and the kaggle kernel CPU is filled up so I would recommend training with less than 100k images"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=All_training_files[:90000]\ny=boolean_labels[:90000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_val,y_val=All_val_files,boolean_val_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating full training and validation data batches\nFull_training_data=create_data_batches(X,y)\nFull_validation_data=create_data_batches(X_val,y_val,valid_data=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(Full_training_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_model=create_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create full model callbacks\n\n# TensorBoard callback\nfull_model_tensorboard = create_tensorboard_callback()\n\n# Early stopping callback\nfull_model_early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\",\n                                                             patience=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_EPOCHS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_model.fit(x=Full_training_data,\n            epochs=NUM_EPOCHS,\n            validation_data=Full_validation_data,\n            validation_freq=1,\n            callbacks=[early_stopping])\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Storing all the test file paths \nfemale_test_files=[]\nfemale_test=list()\nmale_test=list()\nfemale_test_files=os.listdir(Test_female_path)\nmale_test_files=os.listdir(Test_male_path)\nfor i in range(len(os.listdir(Test_female_path))):\n    female_test.append(Test_female_path+\"/\"+str(female_test_files[i]))\nfor i in range(len(os.listdir(Test_male_path))):\n    male_test.append(Test_male_path+\"/\"+str(male_test_files[i]))\n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a test Dataframe\nTest_df=pd.DataFrame()\nTest_df=pd.DataFrame({\"ID\":female_test,\"Target\":\"Female\"})\nnew_test_row=pd.DataFrame({\"ID\":male_test,\"Target\":\"Male\"})\nTest_df=Test_df.append(new_test_row,ignore_index=False)\n#Shuffling the data frame\nTest_df=Test_df.sample(frac=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(Test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test,y_test=Test_df[\"ID\"][:10000],Test_df[\"Target\"][:10000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data=create_data_batches(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 3: Making Predictions on the entire test data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making Predictions on the entire data set\ntest_predictions=full_model.predict(test_data,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predictions.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images,test_labels=unbatchify(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pred(prediction_probabilities=test_predictions,\n          labels=test_labels,\n          images=test_images,n=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_test_25_images(images,label,predictions):\n    # setup a figure \n    plt.figure(figsize=(10,10))\n    # loop through 25 images\n    for i in range(25):\n        # Create subplots (5 rows,5 columns)\n        ax=plt.subplot(5,5,i+1)\n        # Display an image\n        plot_test_pred(prediction_probabilities=predictions, labels=label, images=images, n=i)\n        \n        # Turn the grid lines off\n        plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pred(prediction_probabilities=test_predictions, labels=test_labels, images=test_images, n=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_test_pred(prediction_probabilities, labels, images, n=0):\n    \n    pred_prob, true_label, image = prediction_probabilities[n], labels[n], images[n]\n  \n    # Get the pred label\n    pred_label = get_pred_label(pred_prob)\n  \n  # Plot image & remove ticks\n    plt.imshow(image)\n    plt.xticks([])\n    plt.yticks([])\n\n  # Change the color of the title depending on if the prediction is right or wrong\n    \n    color = \"green\"\n\n    plt.title(\"{} {:2.0f}%\".format(pred_label,\n                                      np.max(pred_prob)*100),\n                                      color=color)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_test_25_images(images=test_images,label=test_labels,predictions=test_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}